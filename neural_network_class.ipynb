{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x_iris = iris['data']\n",
    "y_iris = map(lambda x: np.array([1 if i == x else 0 for i in range(3)]),\n",
    "        iris['target'])\n",
    "y_iris = np.array(y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigmoid = np.vectorize(lambda x: 1.0/(1.0+np.exp(-x)))\n",
    "sig = lambda x: 1.0/(1.0+np.exp(-x))\n",
    "sig_d = lambda x: sig(x) * (1 - sig(x))\n",
    "sigmoid_d = np.vectorize(lambda x: sig(x) * (1 - sig(x)))\n",
    "\n",
    "tanh_d = lambda x: 1 - np.square(np.tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss(y, yhat):\n",
    "    return np.sum(-(y*np.log(yhat) + (1 - y)*np.log(1 - yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class neural_network:\n",
    "    \n",
    "    def __init__(self, sizes, activation = sigmoid, act_d = sigmoid_d):\n",
    "        '''\n",
    "        one required arguement: a list with the layer sizes\n",
    "        can be used for classification or regression\n",
    "        '''\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(x) for x in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) \n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.a = [np.zeros(x) for x in sizes]\n",
    "        self.a_vec = []\n",
    "        self.activation = activation\n",
    "        self.act_d = act_d\n",
    "        self.z = [np.zeros(x) for x in sizes[1:]]\n",
    "        self.z_vec = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict_vec(self,x):\n",
    "        self.a_vec = []\n",
    "        self.z_vec = []\n",
    "        self.a_vec = [x]\n",
    "        m = x.shape[0]\n",
    "        biases = [np.matlib.repmat(b, m, 1) for b in self.biases]\n",
    "        for w, b in zip(self.weights, biases):\n",
    "            z = np.dot(w, x.T).T + b\n",
    "            self.z_vec.append(z)\n",
    "            x = sig(z)\n",
    "            self.a_vec.append(x)\n",
    "        \n",
    "        return x      \n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        input:\n",
    "            - x, a 2D numpy array\n",
    "        output:\n",
    "            predicted values\n",
    "        '''\n",
    "        out = []\n",
    "        for i in x:\n",
    "            for w, b in zip(self.weights, self.biases):\n",
    "                i = self.activation(np.dot(w, i)+b)\n",
    "                \n",
    "            out.append(i)\n",
    "            \n",
    "        return np.array(out)\n",
    "    \n",
    "    \n",
    "    def forward_prop(self, x):\n",
    "        '''\n",
    "        input:\n",
    "            - x, a single observation\n",
    "        output:\n",
    "            predictions for x\n",
    "            \n",
    "        This method can be used for prediction, but it should only be used\n",
    "        as part of training the neural network. The main difference is that\n",
    "        forward_prop() records the activation vectors(a) and output vectors(z)\n",
    "        '''\n",
    "        self.a[0] = x\n",
    "        for i, w in enumerate(self.weights):\n",
    "            b = self.biases[i]\n",
    "            self.z[i] = np.dot(w,x) + b\n",
    "            x = self.activation(self.z[i])\n",
    "            self.a[i+1] = x\n",
    "            \n",
    "            \n",
    "        return self.a[-1]\n",
    "                \n",
    "    \n",
    "    def gradient_descent(self, x, y, lr):\n",
    "        m = len(x)\n",
    "        delta_weights = [np.zeros((self.sizes[l+1], self.sizes[l]))\n",
    "                 for l in range(len(self.sizes[:-1]))]\n",
    "\n",
    "        delta_biases = [np.zeros(l) for l in self.sizes[1:]]\n",
    "\n",
    "        for i in range(m):\n",
    "            w_grads, b_grads = self.back_prop(x[i], y[i])\n",
    "            delta_weights = [dw + wg for dw, wg in zip(delta_weights, w_grads)]\n",
    "            delta_biases = [db + bg for db, bg in zip(delta_biases, b_grads)]\n",
    "            \n",
    "        \n",
    "        self.weights = [w - lr * wg/m for\n",
    "                        wg, w in zip(delta_weights, self.weights)]\n",
    "        self.biases = [b - lr * bg/m for bg,b in zip(delta_biases, self.biases)]\n",
    "        \n",
    "        \n",
    "    def gd_vec(self, x, y, lr, l2):\n",
    "        m = len(x)\n",
    "        delta_weights, delta_biases = self.bp_vec(x, y)          \n",
    "        \n",
    "        self.weights = [w - lr * wg/m for\n",
    "                        wg, w in zip(delta_weights, self.weights)]\n",
    "        self.biases = [b - lr * bg/m for bg,b in zip(delta_biases, self.biases)]\n",
    "        \n",
    "    \n",
    "    def fit(self, x, y, batch_size, learning_rate = 0.01, epochs = 1, l2 = 1e-4,\n",
    "           return_cost = False): \n",
    "        '''\n",
    "        train the neural network using minibatch gradient descent\n",
    "        '''\n",
    "        if return_cost:\n",
    "            cost = []\n",
    "        for e in xrange(epochs):\n",
    "            # create mini batches for minibatch gradient descent\n",
    "            m = len(x)\n",
    "            index = np.array(range(m))\n",
    "            np.random.shuffle(index)\n",
    "            batch_size = 8\n",
    "            num_batches = round(m/batch_size,0)\n",
    "            batches = np.array_split(index, num_batches)\n",
    "            for batch in batches:\n",
    "                self.gd_vec(x[batch], y[batch], learning_rate, l2)\n",
    "            if return_cost:\n",
    "                cost.append(log_loss(y, self.predict_vec(x)))\n",
    "        \n",
    "        if return_cost:\n",
    "            return cost\n",
    "        \n",
    "    \n",
    "    def gradient_checking(self, x, y, epsilon):\n",
    "        '''\n",
    "        function to check the implementation of back_prop()\n",
    "        '''\n",
    "        original_weights = [l*1 for l in self.weights]\n",
    "        grad_approx = [np.zeros((j, i)) \n",
    "                       for i, j in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "        w_grads, b_grads = self.back_prop(x, y)\n",
    "        for l in xrange(self.num_layers - 1):\n",
    "            lshape = self.weights[l].shape\n",
    "            indicies = [(r, c) for c in xrange(lshape[1])\n",
    "                       for r in xrange(lshape[0])]\n",
    "            for i in indicies:\n",
    "                self.weights[l][i] += epsilon\n",
    "                theta_plus = log_loss(y, self.predict([x])[0])\n",
    "                self.weights[l][i] -= 2*epsilon\n",
    "                theta_minus = log_loss(y, self.predict([x])[0])\n",
    "                grad_approx[l][i] = (theta_plus - theta_minus)/(2*epsilon)\n",
    "                self.weights[l][i] += epsilon\n",
    "                      \n",
    "        b_grad_approx = [np.zeros(l) for l in self.sizes[1:]]\n",
    "        original_biases = [b*1 for b in self.biases]\n",
    "        for l in xrange(self.num_layers - 1):\n",
    "            b_shape = len(self.biases[l])\n",
    "            for i in xrange(b_shape):                \n",
    "                self.biases[l][i] += epsilon\n",
    "                theta_plus = log_loss(y, self.predict([x])[0])\n",
    "                self.biases[l][i] -= 2*epsilon\n",
    "                theta_minus = log_loss(y, self.predict([x])[0])\n",
    "                b_grad_approx[l][i] = (theta_plus - theta_minus)/(2*epsilon)\n",
    "                self.biases[l][i] += epsilon\n",
    "        # print some information for gradient checking\n",
    "        for l in xrange(self.num_layers - 1):\n",
    "            print l\n",
    "            print 'weights'\n",
    "            print grad_approx[l]\n",
    "            print w_grads[l]\n",
    "            print 'difference'\n",
    "            print grad_approx[l] - w_grads[l]\n",
    "            print '----------------'\n",
    "            print 'biases'\n",
    "            print b_grad_approx[l]\n",
    "            print b_grads[l]\n",
    "            print 'difference'\n",
    "            print b_grad_approx[l] - b_grads[l]\n",
    "            print '_________________________________'  \n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        '''\n",
    "        computes the gradients for gradient_descent\n",
    "        '''\n",
    "        nabla_w = [None for l in self.weights]\n",
    "        nabla_b = [None for l in self.weights]\n",
    "        deltas = [None for l in self.sizes]\n",
    "        yhat = self.forward_prop(x)\n",
    "        deltas[-1] = yhat - y\n",
    "        for l in range(1, self.num_layers - 1)[::-1]:\n",
    "            w = self.weights[l]\n",
    "            a = self.a[l]\n",
    "            z = self.z[l-1]\n",
    "            deltas[l] = np.dot(w.T, deltas[l+1]) * self.act_d(z)\n",
    "        for l in range(0, self.num_layers-1):\n",
    "            nabla_w[l] =  np.outer(deltas[l+1], self.a[l].T)\n",
    "            nabla_b[l] = deltas[l+1]\n",
    "        return nabla_w, nabla_b\n",
    "\n",
    "\n",
    "    def bp_vec(self, x, y):\n",
    "        nabla_w = [None for l in self.weights]\n",
    "        nabla_b = [None for l in self.weights]\n",
    "        deltas = [None for l in self.sizes]\n",
    "        yhat = self.predict_vec(x)\n",
    "        deltas[-1] = yhat - y\n",
    "        for l in range(1, self.num_layers - 1)[::-1]:\n",
    "            w = self.weights[l]\n",
    "            a = self.a_vec[l]\n",
    "            z = self.z_vec[l-1]\n",
    "            deltas[l] = (np.dot(w.T, deltas[l+1].T) * sig_d(z).T).T\n",
    "        for l in range(0, self.num_layers-1):\n",
    "            nabla_w[l] =  np.dot(deltas[l+1].T, self.a_vec[l])\n",
    "            nabla_b[l] = deltas[l+1]\n",
    "        return nabla_w, [b.sum(axis = 0) for b in nabla_b]\n",
    "\n",
    "               \n",
    "my_nn = neural_network([4,8,3])\n",
    "cost = my_nn.fit(x_iris, y_iris, batch_size = 8,\n",
    "                 epochs = 1000, return_cost = True)\n",
    "\n",
    "\n",
    "# print bp_vecw\n",
    "# print bpw\n",
    "# bp_vecw[0] == bpw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1aebb2b0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAECCAYAAAAfE3cCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niLSgAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ae0f390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(cost)/len(x_iris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5869998931884766"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "my_nn = neural_network([4,8,3])\n",
    "cost = my_nn.fit(x_iris, y_iris, batch_size = 8,\n",
    "                 epochs = 1000, return_cost = True)\n",
    "\n",
    "t1 = time.time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4649999141693115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "my_nn = neural_network([4,8,3])\n",
    "my_nn.fit(x_iris, y_iris, batch_size = 8,\n",
    "                 epochs = 1000)\n",
    "\n",
    "t1 = time.time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.092999935150146"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "cost = []\n",
    "my_nn = neural_network([4,8,3])\n",
    "for j in xrange(1000):\n",
    "    my_nn.gradient_descent(x_iris, y_iris, 0.01)\n",
    "    cost.append(log_loss(y_iris, my_nn.predict_vec(x_iris)))\n",
    "    \n",
    "t1 = time.time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.562000036239624"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "cost = []\n",
    "my_nn = neural_network([4,8,3])\n",
    "for j in xrange(1000):\n",
    "    my_nn.gradient_descent(x_iris, y_iris, 0.01)\n",
    "    cost.append(log_loss(y_iris, my_nn.predict(x_iris)))\n",
    "    \n",
    "t1 = time.time()\n",
    "t1 - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,1,1],[1,1,1]]).sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8L, 4L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_or = np.random.randint(2, size = (30,2))\n",
    "x_or = np.array([[1,1], [1,0], [0,1], [0,0]])\n",
    "y_or = np.array(map(lambda x: [(x[0]==1 or x[1]==1) and (x[0]!=1 or x[1]!= 1)],\n",
    "                           x_or))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01027788]\n",
      " [ 0.98909645]\n",
      " [ 0.98908146]\n",
      " [ 0.01122895]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18f88320>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAECCAYAAAD5OrxGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1890d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_nn = neural_network([2,4,1])\n",
    "cost = []\n",
    "for i in xrange(10000):\n",
    "    my_nn.gradient_descent(x_or, y_or, 0.1)\n",
    "    cost.append(log_loss( y_or, my_nn.predict(x_or)))\n",
    "    \n",
    "print my_nn.predict(x_or)\n",
    "plt.plot(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
