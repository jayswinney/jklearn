{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x_iris = iris['data']\n",
    "y_iris = map(lambda x: np.array([1 if i == x else 0 for i in range(3)]),\n",
    "        iris['target'])\n",
    "y_iris = np.array(y_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigmoid = np.vectorize(lambda x: 1.0/(1.0+np.exp(-x)))\n",
    "sig = lambda x: 1.0/(1.0+np.exp(-x))\n",
    "sig_d = lambda x: sig(x) * (1 - sig(x))\n",
    "sigmoid_d = np.vectorize(lambda x: sig(x) * (1 - sig(x)))\n",
    "\n",
    "tanh_d = lambda x: 1 - np.square(np.tanh(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_loss(y, yhat):\n",
    "    return np.sum(-(y*np.log(yhat) + (1 - y)*np.log(1 - yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3L, 8L)\n",
      "(4L, 3L)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (8,3) and (4,3) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-43831c7474be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[0mmy_nn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mneural_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m \u001b[0mmy_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbp_vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_iris\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_iris\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-43831c7474be>\u001b[0m in \u001b[0;36mbp_vec\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#* self.act_d(z)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0mnabla_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (8,3) and (4,3) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "class neural_network:\n",
    "    \n",
    "    def __init__(self, sizes, activation = sigmoid, act_d = sigmoid_d):\n",
    "        '''\n",
    "        one required arguement: a list with the layer sizes\n",
    "        can be used for classification or regression\n",
    "        '''\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(x) for x in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) \n",
    "                        for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "        self.a = [np.zeros(x) for x in sizes]\n",
    "        self.a_vec = []\n",
    "        self.activation = activation\n",
    "        self.act_d = act_d\n",
    "        self.z = [np.zeros(x) for x in sizes[1:]]\n",
    "        self.z_vec = []\n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict_vec(self,x):\n",
    "        self.a_vec = [x]\n",
    "        m = x.shape[0]\n",
    "        biases = [np.matlib.repmat(b, m, 1) for b in self.biases]\n",
    "        for w, b in zip(self.weights, biases):\n",
    "            z = np.dot(w, x.T).T + b\n",
    "            self.z_vec.append(z)\n",
    "            x = sig(z)\n",
    "            self.a_vec.append(x)\n",
    "        \n",
    "        return x      \n",
    "        \n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        input:\n",
    "            - x, a 2D numpy array\n",
    "        output:\n",
    "            predicted values\n",
    "        '''\n",
    "        out = []\n",
    "        for i in x:\n",
    "            for w, b in zip(self.weights, self.biases):\n",
    "                i = self.activation(np.dot(w, i)+b)\n",
    "                \n",
    "            out.append(i)\n",
    "            \n",
    "        return np.array(out)\n",
    "    \n",
    "    \n",
    "    def forward_prop(self, x):\n",
    "        '''\n",
    "        input:\n",
    "            - x, a single observation\n",
    "        output:\n",
    "            predictions for x\n",
    "            \n",
    "        This method can be used for prediction, but it should only be used\n",
    "        as part of training the neural network. The main difference is that\n",
    "        forward_prop() records the activation vectors(a) and output vectors(z)\n",
    "        '''\n",
    "        self.a[0] = x\n",
    "        for i, w in enumerate(self.weights):\n",
    "            b = self.biases[i]\n",
    "            self.z[i] = np.dot(w,x) + b\n",
    "            x = self.activation(self.z[i])\n",
    "            self.a[i+1] = x\n",
    "            \n",
    "            \n",
    "        return self.a[-1]\n",
    "                \n",
    "    \n",
    "    def gradient_descent(self, x, y, lr):\n",
    "        m = len(x)\n",
    "        delta_weights = [np.zeros((self.sizes[l+1], self.sizes[l]))\n",
    "                 for l in range(len(self.sizes[:-1]))]\n",
    "\n",
    "        delta_biases = [np.zeros(l) for l in self.sizes[1:]]\n",
    "\n",
    "        for i in range(m):\n",
    "            w_grads, b_grads = self.back_prop(x[i], y[i])\n",
    "            delta_weights = [dw + wg for dw, wg in zip(delta_weights, w_grads)]\n",
    "            delta_biases = [db + bg for db, bg in zip(delta_biases, b_grads)]\n",
    "        \n",
    "        self.weights = [w - lr * wg/m for\n",
    "                        wg, w in zip(delta_weights, self.weights)]\n",
    "        self.biases = [b - lr * bg/m for bg,b in zip(delta_biases, self.biases)]\n",
    "\n",
    "    \n",
    "    def gradient_checking(self, x, y, epsilon):\n",
    "        '''\n",
    "        function to check the implementation of back_prop()\n",
    "        '''\n",
    "        original_weights = [l*1 for l in self.weights]\n",
    "        grad_approx = [np.zeros((j, i)) \n",
    "                       for i, j in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "        w_grads, b_grads = self.back_prop(x, y)\n",
    "        for l in xrange(self.num_layers - 1):\n",
    "            lshape = self.weights[l].shape\n",
    "            indicies = [(r, c) for c in xrange(lshape[1])\n",
    "                       for r in xrange(lshape[0])]\n",
    "            for i in indicies:\n",
    "                self.weights[l][i] += epsilon\n",
    "                theta_plus = log_loss(y, self.predict([x])[0])\n",
    "                self.weights[l][i] -= 2*epsilon\n",
    "                theta_minus = log_loss(y, self.predict([x])[0])\n",
    "                grad_approx[l][i] = (theta_plus - theta_minus)/(2*epsilon)\n",
    "                self.weights[l][i] += epsilon\n",
    "                      \n",
    "        b_grad_approx = [np.zeros(l) for l in self.sizes[1:]]\n",
    "        original_biases = [b*1 for b in self.biases]\n",
    "        for l in xrange(self.num_layers - 1):\n",
    "            b_shape = len(self.biases[l])\n",
    "            for i in xrange(b_shape):                \n",
    "                self.biases[l][i] += epsilon\n",
    "                theta_plus = log_loss(y, self.predict([x])[0])\n",
    "                self.biases[l][i] -= 2*epsilon\n",
    "                theta_minus = log_loss(y, self.predict([x])[0])\n",
    "                b_grad_approx[l][i] = (theta_plus - theta_minus)/(2*epsilon)\n",
    "                self.biases[l][i] += epsilon\n",
    "        # print some information for gradient checking\n",
    "        for l in xrange(self.num_layers - 1):\n",
    "            print l\n",
    "            print 'weights'\n",
    "            print grad_approx[l]\n",
    "            print w_grads[l]\n",
    "            print 'difference'\n",
    "            print grad_approx[l] - w_grads[l]\n",
    "            print '----------------'\n",
    "            print 'biases'\n",
    "            print b_grad_approx[l]\n",
    "            print b_grads[l]\n",
    "            print 'difference'\n",
    "            print b_grad_approx[l] - b_grads[l]\n",
    "            print '_________________________________'  \n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        '''\n",
    "        computes the gradients for gradient_descent\n",
    "        '''\n",
    "        nabla_w = [None for l in self.weights]\n",
    "        nabla_b = [None for l in self.weights]\n",
    "        deltas = [None for l in self.sizes]\n",
    "        yhat = self.forward_prop(x)\n",
    "        deltas[-1] = yhat - y\n",
    "        for l in range(1, self.num_layers - 1)[::-1]:\n",
    "            w = self.weights[l]\n",
    "            a = self.a[l]\n",
    "            z = self.z[l-1]\n",
    "            deltas[l] = np.dot(w.T, deltas[l+1]) * self.act_d(z)\n",
    "        for l in range(0, self.num_layers-1):\n",
    "            nabla_w[l] =  np.outer(deltas[l+1], self.a[l].T)\n",
    "            nabla_b[l] = deltas[l+1]\n",
    "        return nabla_w, nabla_b\n",
    "\n",
    "\n",
    "    def bp_vec(self, x, y):\n",
    "        nabla_w = [None for l in self.weights]\n",
    "        nabla_b = [None for l in self.weights]\n",
    "        deltas = [None for l in self.sizes]\n",
    "        yhat = self.predict_vec(x)\n",
    "        deltas[-1] = yhat - y\n",
    "#         print deltas[-1]\n",
    "        for l in range(1, self.num_layers - 1)[::-1]:\n",
    "#             print l\n",
    "            w = self.weights[l]\n",
    "            a = self.a_vec[l]\n",
    "            z = self.z_vec[l-1]\n",
    "            print w.shape\n",
    "            print deltas[l+1].shape\n",
    "            deltas[l] = np.dot(w.T, deltas[l+1]) #* self.act_d(z)\n",
    "        for l in range(0, self.num_layers-1):\n",
    "            nabla_w[l] =  np.outer(deltas[l+1], self.a[l].T)\n",
    "            nabla_b[l] = deltas[l+1]\n",
    "        return nabla_w, nabla_b\n",
    "\n",
    "               \n",
    "my_nn = neural_network([4,8,3])\n",
    "my_nn.bp_vec(x_iris[:4], y_iris[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.22829868,  0.06247426,  0.84405512],\n",
       "       [ 0.2187139 ,  0.37993216,  0.68170835],\n",
       "       [ 0.2010883 ,  0.07114846,  0.87061264],\n",
       "       [ 0.12770588,  0.32291248,  0.86931497],\n",
       "       [ 0.2169575 ,  0.18476874,  0.67421946],\n",
       "       [ 0.21265259,  0.16483792,  0.79670258],\n",
       "       [ 0.11950778,  0.12056203,  0.92373197],\n",
       "       [ 0.11120537,  0.09722595,  0.93837569],\n",
       "       [ 0.23406388,  0.44197255,  0.64175415],\n",
       "       [ 0.15759066,  0.15264049,  0.94338488],\n",
       "       [ 0.1066621 ,  0.07974265,  0.92136324],\n",
       "       [ 0.23746025,  0.16887755,  0.68591545],\n",
       "       [ 0.20489375,  0.49557053,  0.70289791],\n",
       "       [ 0.20333621,  0.07959687,  0.83930828],\n",
       "       [ 0.2647913 ,  0.28265737,  0.60158485],\n",
       "       [ 0.16021146,  0.13150102,  0.92958819],\n",
       "       [ 0.26792359,  0.06805299,  0.83317218],\n",
       "       [ 0.21332426,  0.19053514,  0.9168237 ],\n",
       "       [ 0.1487749 ,  0.15329583,  0.92982245],\n",
       "       [ 0.08738166,  0.08934971,  0.95225028],\n",
       "       [ 0.15398976,  0.28811685,  0.84309403],\n",
       "       [ 0.08043943,  0.09121853,  0.95805574],\n",
       "       [ 0.18361329,  0.45149483,  0.78846565],\n",
       "       [ 0.1438596 ,  0.29797208,  0.88746049],\n",
       "       [ 0.16460518,  0.08600419,  0.89953056],\n",
       "       [ 0.17565616,  0.07500496,  0.86745755],\n",
       "       [ 0.08091535,  0.11817357,  0.95293126],\n",
       "       [ 0.22214383,  0.3005631 ,  0.66096919],\n",
       "       [ 0.15843495,  0.32445353,  0.9071608 ],\n",
       "       [ 0.07910833,  0.09171016,  0.95216203]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_nn = neural_network([4,8,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8L, 4L)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658],\n",
       "       [-0.85461502, -0.31632604, -1.27671658]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.matlib\n",
    "np.matlib.repmat(np.random.randn(3), 9, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.21948380e-01,   8.59006132e-01,   3.91307180e-01,\n",
       "          4.71906659e-01,   6.49766459e-01,   2.35201531e-01,\n",
       "          4.73742995e-01,   5.35409453e-01],\n",
       "       [  3.04884003e-01,   9.71714292e-01,   1.34622117e-02,\n",
       "          1.50664960e-01,   3.15845923e-02,   5.21526778e-02,\n",
       "          8.29131295e-01,   2.38229331e-03],\n",
       "       [  4.24496680e-01,   4.36094260e-01,   7.69358193e-01,\n",
       "          3.61449598e-01,   5.53529453e-01,   1.95597158e-01,\n",
       "          4.32612861e-01,   9.98429452e-01],\n",
       "       [  9.65477893e-01,   2.94265051e-02,   5.53244535e-02,\n",
       "          3.11988450e-01,   2.12791237e-01,   2.91425806e-01,\n",
       "          5.95029697e-01,   1.55076824e-02],\n",
       "       [  4.14971192e-01,   7.81680560e-01,   5.04221193e-01,\n",
       "          3.52596977e-01,   2.37939245e-01,   3.11664184e-01,\n",
       "          6.04624785e-01,   8.52887565e-01],\n",
       "       [  9.99728001e-01,   1.19650641e-03,   9.98187057e-01,\n",
       "          6.74835299e-01,   4.32459497e-02,   9.98751811e-01,\n",
       "          5.92711999e-01,   9.99785899e-01],\n",
       "       [  9.07154302e-01,   7.79625964e-01,   6.02290431e-02,\n",
       "          1.17721314e-01,   5.37697438e-03,   1.84068728e-01,\n",
       "          8.76154819e-01,   6.27277949e-02],\n",
       "       [  8.21255960e-01,   1.72121937e-02,   6.54581187e-01,\n",
       "          5.43487785e-01,   8.80263655e-01,   3.80064041e-01,\n",
       "          2.65660464e-01,   9.73463639e-01],\n",
       "       [  2.11818617e-02,   9.69123002e-01,   4.57133810e-03,\n",
       "          3.15290808e-01,   7.04186827e-01,   1.43112800e-02,\n",
       "          5.46252484e-01,   2.13235521e-04],\n",
       "       [  1.99703796e-02,   5.84325770e-01,   4.76873212e-01,\n",
       "          7.90355286e-01,   9.94520236e-01,   2.63255749e-01,\n",
       "          1.50230402e-01,   3.04781392e-01],\n",
       "       [  9.68018674e-01,   2.20188575e-01,   9.99968425e-01,\n",
       "          6.62021811e-01,   8.26546521e-02,   9.96948888e-01,\n",
       "          5.31190104e-01,   9.99999996e-01],\n",
       "       [  5.28668588e-02,   9.48672406e-01,   9.29586734e-01,\n",
       "          7.22521954e-01,   8.05144417e-01,   7.81421019e-01,\n",
       "          3.97137748e-01,   9.42028489e-01],\n",
       "       [  1.22885993e-01,   9.74564346e-01,   9.45260654e-01,\n",
       "          7.40481761e-01,   4.31944750e-01,   9.46837881e-01,\n",
       "          5.63238896e-01,   6.68520560e-01],\n",
       "       [  2.52355472e-02,   7.14069373e-01,   1.48261691e-01,\n",
       "          7.05409308e-01,   9.83419538e-01,   1.62547994e-01,\n",
       "          2.28599193e-01,   1.81812451e-02],\n",
       "       [  9.49000669e-01,   2.72328966e-01,   3.05571646e-01,\n",
       "          4.52228328e-01,   6.27645906e-02,   8.59116287e-01,\n",
       "          7.29285858e-01,   1.19269388e-02],\n",
       "       [  2.69131061e-03,   9.63250158e-01,   1.37547688e-01,\n",
       "          6.86109789e-01,   9.89659179e-01,   6.48188115e-02,\n",
       "          2.20899481e-01,   3.53930953e-02],\n",
       "       [  2.37536519e-01,   9.85339982e-01,   3.18053305e-01,\n",
       "          3.05909941e-01,   4.72454222e-02,   4.06065215e-01,\n",
       "          7.89470230e-01,   1.55852985e-01],\n",
       "       [  3.38947218e-01,   9.71515796e-01,   4.01460189e-01,\n",
       "          3.41292566e-01,   5.38172556e-02,   5.23620635e-01,\n",
       "          7.72885763e-01,   1.93747951e-01],\n",
       "       [  7.10941860e-01,   5.59937762e-01,   9.99973472e-01,\n",
       "          7.85198029e-01,   4.06112983e-01,   9.95871923e-01,\n",
       "          3.85016319e-01,   9.99999993e-01],\n",
       "       [  4.93938453e-01,   7.95602541e-03,   4.19646766e-03,\n",
       "          4.67212627e-01,   9.86851893e-01,   1.48829699e-02,\n",
       "          1.81105446e-01,   9.30617662e-04],\n",
       "       [  4.87779452e-02,   9.89997509e-01,   1.05065411e-05,\n",
       "          8.14855505e-02,   8.85981323e-02,   8.74674046e-04,\n",
       "          8.43730392e-01,   6.08527484e-09],\n",
       "       [  8.19533292e-01,   1.17396822e-01,   8.32740728e-01,\n",
       "          5.71609942e-01,   5.60267850e-01,   7.58064498e-01,\n",
       "          4.26846684e-01,   9.50062579e-01],\n",
       "       [  5.12529983e-01,   5.51917063e-01,   9.88645115e-01,\n",
       "          9.01371071e-01,   7.78417471e-01,   9.95655267e-01,\n",
       "          3.81287930e-01,   6.60398385e-01],\n",
       "       [  4.19953952e-01,   5.19651984e-01,   1.32279223e-04,\n",
       "          2.71052229e-01,   4.05340461e-01,   2.16467884e-02,\n",
       "          6.66955454e-01,   2.52630929e-08],\n",
       "       [  5.94318830e-01,   3.41804026e-03,   8.10165698e-01,\n",
       "          8.36920324e-01,   9.97049969e-01,   6.13894503e-01,\n",
       "          8.29079496e-02,   9.38017652e-01],\n",
       "       [  9.02969202e-01,   8.36128975e-01,   6.02574382e-01,\n",
       "          1.74261022e-01,   5.61273150e-03,   5.39548818e-01,\n",
       "          8.56265528e-01,   9.39539916e-01],\n",
       "       [  8.60489984e-01,   2.08390485e-02,   8.63482666e-01,\n",
       "          6.61739506e-01,   8.58979918e-01,   7.57917216e-01,\n",
       "          2.77746145e-01,   9.74376516e-01],\n",
       "       [  9.89688938e-01,   1.97543666e-02,   9.99042030e-01,\n",
       "          7.18387447e-01,   2.30837070e-01,   9.94936500e-01,\n",
       "          4.54002076e-01,   9.99985022e-01],\n",
       "       [  5.08283981e-02,   6.22778945e-01,   1.11750775e-01,\n",
       "          7.46230735e-01,   9.76692160e-01,   3.09835573e-01,\n",
       "          2.58050960e-01,   1.75273555e-03],\n",
       "       [  2.99535264e-02,   9.96024571e-01,   2.90444446e-04,\n",
       "          2.55325526e-01,   1.60652925e-01,   2.48972449e-02,\n",
       "          8.06453861e-01,   3.32577294e-08]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(np.dot(w, np.random.randn(30, 4).T).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_or = np.random.randint(2, size = (30,2))\n",
    "x_or = np.array([[1,1], [1,0], [0,1], [0,0]])\n",
    "y_or = np.array(map(lambda x: [(x[0]==1 or x[1]==1) and (x[0]!=1 or x[1]!= 1)],\n",
    "                           x_or))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01027788]\n",
      " [ 0.98909645]\n",
      " [ 0.98908146]\n",
      " [ 0.01122895]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18f88320>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAECCAYAAAD5OrxGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHbNJREFUeJzt3XuYHGWZ/vHvJCQhkAMEgYggKsLLQQWDbERiOCigC2Uh\nu7oivygqIaByshAQAUUQZbWQIIJrCASW5bAgWFugkIVFOSkoouEgD4bVn6isGxGSAAFymP3jrbE6\nY9I9M93V1d11f66rr57p6ul65p6ep6rr8FZff38/IiJSHaPKLkBERNpLjV9EpGLU+EVEKkaNX0Sk\nYtT4RUQqRo1fRKRiNqg30Tk3GpgH7AD0A0eb2aM1008EPgEsyR6aY2ZPFFSriIi0QN3GDxwMrDGz\nGc65vYEvA4fUTJ8GzDKzh4oqUEREWqvuph4zS4A52bevA54d9JTdgdOcc3c7505tfXkiItJqDbfx\nm9lq59wC4ELg6kGTr8EvGPYDZjjnDmp5hSIi0lJD2rlrZkfgt/PPc86Nr5k018z+YmYrgVuAt7a+\nRBERaaVGO3dnAVub2VeAFcAa/E5enHOTgUXOuZ2BF/Fr/fMbzO8lYFyzRYuIVExfS1+s3iBt2dr9\nAmAqMAb4CjABmGBm85xzhwEnAi8Dt5vZWQ3m10+Lf4EupixyyiKnLHLKoiB1G38B9IfMKYucssgp\ni5yyKIhO4BIRqRg1fhGRilHjFxGpGDV+EZGKUeMXEakYNX4RkYpR4xcRqRg1fhGRilHjFxGpGDV+\nEZGKUeMXEakYNX4RkYpR4xcRqRg1fhGRilHjFxGpGDV+EZGKUeMXEakYNX4RkYpR4xcRqRg1fhGR\nilHjFxGpGDV+EZGKUeMXEakYNX4RkYrZoN5E59xoYB6wA9APHG1mj9ZMD4AzgFXAZWZ2aYG1iohI\nCzRa4z8YWGNmM4DTgS8PTHDOjQHOB/YH9gaOcs5tUe/F+vv7m6tWRESaVrfxm1kCzMm+fR3wbM3k\nnYDFZrbUzFYC9wAz673erC/eShAlO468XBERaVbDbfxmtto5twC4ELi6ZtIkYGnN98uByfVea+nz\nrwDsMuwqRUSkZepu4x9gZkc4504B7nfO7WRmK/BNf2LN0yay9ieCdYoO3/2GEVXam7TtK6cscsoi\npyy8vla+WKOdu7OArc3sK8AKYA35H+JxYHvn3KbAC/jNPF9rNMP43x78+D7Ttr68qap7Qz8t/mN2\nMWWRUxY5ZVGQRpt6bgB2c879CLgVOB54v3NudrZd/zPAbcB9wHwze3oI8xzbTMEiItKcumv82Sad\nf6oz/Wbg5mHOc9wwny8iIi1UxglcavwiIiVS4xcRqZgyGr+28YuIlEhr/CIiFaPGLyJSMdrUIyJS\nMWU0/o1LmKeIiGTKaPxTSpiniIhk2tr4R43qAzV+EZFStbXxT9xoDMBm7ZyniIisra2Nf/KEcQBb\nBVGiSz6KiJSkrQ349a+eDH745p3bOV8REcm1tfFP32XqwJffDaJk/3bOW0REvLY2/hm7bQX+Or3b\nAwuDKLk5iJId2lmDiEjV9bX5Auj9QF8QJbvhFwD7AiuBucDZaRwua2cxJdNFJnLKIqcscsqiIKU0\nfoAgSvqAQ4EY2Bb4E/DJNA5vbGdBJdKbOqcscsoipywKUlrjHxBEyXjgJODz+HF8rgaOTePwL+0s\nrAR6U+eURU5Z5JRFQUpv/AOCKNkRuAL4O+CPwAfTOLy3jbW1m97UOWWRUxY5ZVGQjmn8AEGUbACc\nDHwpe24EfDONw7YW2SZ6U+eURU5Z5JRFQTqq8Q8IomQf4DpgC/yngNlpHK4strS205s6pyxyyiKn\nLArSkY0fIIiS1wA3AXsAC4F/TONweYG1tZve1DllkVMWOWVRkI4dOiGNwz/gD/e8BTgA+FEQJVuU\nW5WISPfr2MYPkMbhC8AhwKXAW4H/UvMXEWlORzd+gDQOVwFHARcCu6DmLyLSlLrb+J1zY4DL8CdY\njQPOMbO0ZvqJwCeAJdlDc8zsiTrzG/E2u+yErwuA44BHgb3TOHxmJK/VIbT9MqcscsoipywK0miN\n/3BgiZnNBN4DXDRo+jRglpntm93qNf2mZId0nkC+5n9zECW6jKOIyDA1avzXA2fWPHfVoOm7A6c5\n5+52zp3a6uIGy5r/icBVwNuB64IoGVP0fEVEekndxm9mL5jZ8865ifiFwOcHPeUaYA6wHzDDOXdQ\nMWXm0jhcA3wcuBU4CJiXbQYSEZEhaHgcv3NuG+BG4FtmtmDQtElmtiz7+hhgMzM7p87LteykgRUv\nr+L0b9/LE797jsMOcHz4wB1b9dIiIp2mpSu3jXbubgn8EPikmd05aNpkYBH+alovAv8OzDezW+vM\nr6U7a4Io2Ry4H3g9cFgah9e26rXbQDuucsoipyxyyqIgjRr/XOADgNU8PA/Y2MzmOecOw29zfxm4\n3czOajC/lv8hgyjZBbgPf9TR3mkc3t/K1y+Q3tQ5ZZFTFjllUZCOHbJhOIIoeS9wM/6w0j3SOHyq\n1fMogN7UOWWRUxY5ZVGQjj+BayjSOPwB8BlgSyANomRCySWJiHSsnmj8mQuBfwF2BebrSB8RkXXr\nmcafHeN/HHAv8EH8WP4iIjJIT2zjrxVEyVTgQWAqcGAah7cXOb8maPtlTlnklEVOWRSk5xo/QBAl\newI/ApYDu6dx+Nui5zkCelPnlEVOWeSURUF6ZlNPrTQOfwx8GpgC3BREyUYllyQi0jF6svEDpHH4\nHfw5B7sB39HOXhERr2cbf+ZY/Jm9h+N3/IqIVF5PbuOvlV2790HgVcB+aRze1c7516HtlzllkVMW\nOWVRkF5f4x+4du8Hsm+vy476ERGprJ5v/ABpHN4NnII/xPOaIEo2KLkkEZHSVKLxZ84HbgL2Ac4u\ntxQRkfL0/Db+WkGUTAZ+BrwRCNM4/I+yakHbL2spi5yyyCmLglSq8QMEUbIr8BPgJfzJXf9dUiml\nZ9FBlEVOWeSURUGqtKkHgDQOfwkcA2wCXB9EyYYllyQi0laVa/wAaRwuAC4FpuFH9RQRqYxKNv7M\nccAvgNlBlHy07GJERNqlctv4awVR8gbg58BYYHoahw+3cfYdlUXJlEVOWeSURUGqvMZPtmP3I8B4\n4NogSsaXXJKISOEq3fgBskM6vwnsDMQllyMiUrjKN/7MycAjwDFBlIRlFyMiUqRKb+OvFUTJm4Cf\nAi8Cb8nG+ClSx2ZRAmWRUxY5ZVEQrfFn0jh8BH+d3inAlUGUjC65JBGRQqjxr+0SIAX2A04ouRYR\nkULU3dTjnBsDXAZsC4wDzjGztGZ6AJwBrAIuM7NLG8yv4z+6BVGyOfAoMBHYNY3DJwqaVcdn0UbK\nIqcscsqiII3W+A8HlpjZTOA9wEUDE7KFwvnA/sDewFHOuS2KKrRd0jhcAnwK2BC4TJt8RKTXNGr8\n1wNn1jx3Vc20nYDFZrbUzFYC9wAzW19i+6VxeD1wA7AX/vKNIiI9o27jN7MXzOx559xE/ELg8zWT\nJwFLa75fDkxufYml+RTwDHBuECVvLLsYEZFWaXglKufcNsCNwLfM7NqaSUvx28EHTASeHcI823r8\n6EilccjdD/2Bf77qZ+y6/at+3d/fT19fyzc3dkUWbaIscsoipyy8ljafRjt3twR+CHzSzO4cNG0M\nfifodOAF4D4gMLOn68yvq3bWBFHSB9wCvBf4UBqH17Xw5bsqi4Ipi5yyyCmLgjRq/HPxFyq3mofn\nARub2Tzn3MH4fQCjgPlmdkmD+XXdHzKIku3wC7hngB3TOFzeopfuuiwKpCxyyiKnLAqiM3eHIIiS\nLwJfAM5P4zBq0ct2ZRYFURY5ZZFTFgXRCVxDcx7wJHB8ECVvLrsYEZFmqPEPQRqHK/AXbhkNfL3k\nckREmqLGP0RpHH4fWAgcEETJgWXXIyIyUmr8w/NZ/HbHr+uMXhHpVmr8w5DG4SLgcuBNwBHlViMi\nMjJq/MN3Jn7M/nOCKJlQdjEiIsOlxj9M2QVaYmAq8OmSyxERGTY1/pGJ8cNTfDaIkkllFyMiMhxq\n/COQxuFS/GGdU4DjSy5HRGRY1PhH7pv4YRyiIEo2KbsYEZGhUuMfoWzMnvPwQ1F/puRyRESGTI2/\nORcD/wucEETJlLKLEREZCjX+JqRx+AJ+rX8iOsJHRLqEGn/zvoM/wue4IEo2LrsYEZFG1PiblMbh\n8/gdvZsBR5ZcjohIQ2r8rXEh/mzek4IoGVt2MSIi9ajxt0Aah8/gN/lsDRxecjkiInWp8bdODKwE\nTtHInSLSydT4WySNw98DVwEOeF/J5YiIrJcaf2sNXJ3rxFKrEBGpQ42/hdI4fAy4DXhnECW7l12P\niMi6qPG33jey+xNKrUJEZD3U+FtvIfAY8KEgSrYquxgRkcHU+FssjcN+4AJgA+BTJZcjIvI3+vr7\n+xs+yTk3Hfiqme076PETgU8AS7KH5pjZE3Veqh/oG2GtXSOIkvHA7/AL1m3SOHxxHU+rRBZDpCxy\nyiKnLArScI3fOXcyMA8Yt47J04BZZrZvdqvX9CsjjcMVwLfxF2qZVXI5IiJrGcqmnsXAoax7ybs7\ncJpz7m7n3Kktraz7XYw/oeuEIEq01iIiHaNh4zezG4FV65l8DTAH2A+Y4Zw7qIW1dbU0Dp8GrgV2\nBN5VcjkiIn+1QZM/P9fMlgE4524B3grc0uBnGu9U6BHx8TOJ5t7F9F2m/ud6nlKZLIZAWeSURU5Z\neC3dajDio3qcc5OBh51zGzvn+vBr/T8bwo/2VeW2w2s37QMeuP/R/1kTRMnrB02vVBYNbspCWSiL\nxlm0zHAafz+Ac+4w59xsM1sKnArcCdwFPGJmt7a6wB5wET7no8suREQEGNrhnC1UucOzgijZkLUP\n7VyRTapcFnUoi5yyyCmLgugEroKlcfgS/nDYzYB/KrkcERE1/jb5NrAGOFaHdopI2dT42yCNw6eA\n7+FPeJtecjkiUnFq/O3zrez+06VWISKVp8bfPncCvwI+GETJ1LKLEZHqUuNvk2zUzouAMcDskssR\nkQpT42+vfwWWA0evWr2m7FpEpKLU+NsojcPlwAJgq5888nTJ1YhIVanxt9/FADff85uy6xCRitKZ\nuyUIomQhsD+waxqHi8qupwPofZFTFjllURCt8Zfjouxeh3aKSNup8Zfjli2mbATw/4IomVJ2MSJS\nLWr8JUjjcPXBe70eYDxwZMnliEjFqPGXZP/p2wK8AHw6iJJmL4gjIjJkavwlmTB+DMAVwDbAIeVW\nIyJVosZfrguz++NLrUJEKkWNv0RpHBpwKzAjiJJpZdcjItWgxl++udm91vpFpC3U+Mu3EDDgQ0GU\nbFl2MSLS+9T4S5bG4Rr8tv6x6ILsItIGavyd4UrgOeCYIErGlV2MiPQ2Nf4OkMbh88ClwJboguwi\nUjA1/s5xEbAaOEkXZBeRIqnxd4g0Dv8/cB3wZuC9JZcjIj1sSI3fOTfdOXfnOh4PnHMPOOfuc85p\nzJnmnZfdn1JqFSLS0xo2fufcycA8YNygx8cA5+PHld8bOMo5t0URRVZFNjb/D4CZQZTsWXY9ItKb\nhrLGvxg4lL+9IMJOwGIzW2pmK4F7gJktrq+KtNYvIoVq2PjN7EZg1TomTQKW1ny/HJjcorqq7C7g\nJ0AYRMnOZRcjIr2nmeGAlwITa76fCDw7hJ9r67UeO9zfZJHGIT9++GnOXfAA79pjm0fLKKokel/k\nlEVOWXgtPdKvmcb/OLC9c25T/LjyM4GvDeHndKiit97riZ674IFRwKN3/PSpN97x06d2SOOw16/M\nrmur5pRFTlkUZDiHc/YDOOcOc87Nzrbrfwa4DbgPmG9mTxdQY+VkwzicjV8wn15yOSLSY/r6+9v6\nSUpL8FzdLIIoGQ08DOwAuDQOn2xXYSXQ+yKnLHLKoiA6gatDpXG4GvgiMBo4o9xqRKSXqPF3thuA\nR4BZQZTsUHYxItIb1Pg7WLat/4v4v9MXyq1GRHqFGn/nuwn4JXBYECW7ll2MiHQ/Nf4Ol631n4Lf\nyfV1jdwpIs1S4+8CaRzehr9E47uBA0suR0S6nBp/9zgJWINf62/mxDsRqTg1/i6RxuHDwOXALsDH\nSi5HRLqYGn93ORN4EfhyECVTyi5GRLqTGn8XSePwj8BZwObAuSWXIyJdSo2/+1wAPAYcFUTJ9LKL\nEZHuo8bfZdI4fAU4Bn945yXa0Ssiw6XG34XSOLwLuAJ4K3BcyeWISJdR4+9enwWWAOcGUbJT2cWI\nSPdQ4+9SaRwuAY4GxgFXaJOPiAyVGn8XS+PwRuAqYA/g5JLLEZEuocbf/Y4D/gicpaN8RGQo1Pi7\nXBqHzwIfwV+w5d91YpeINKLG3wPSOLwDf2LXa4EFGsFTROpR4+8d5wC3AwHa3i8idehi6+VpeRZB\nlGwJ/Bx4NfD+NA6TVr5+gfS+yCmLnLIoiBp/eQrJIoiSacDd2bcz0jh8qNXzKIDeFzllkVMWBdGm\nnh6TxuHPgcOB8UAaRMnWJZckIh1Gjb8HpXH4PeBU4DXAfwZRsnnJJYlIB6m7qcc5Nwq4GHgL8DJw\npJk9WTP9ROAT+KEDAOaY2RN15qePbrlCs8iO7Pln/JW7HgL2S+PwuaLm1yS9L3LKIqcsCtJojf8Q\nYKyZvQO/BhkPmj4NmGVm+2a3ek1f2iiNw3780T3fwQ/m9v0gSiaXW5WIdIJGjX8v4FYAM7sfeNug\n6bsDpznn7nbOnVpAfdKErPl/Ej+sw57AndrsIyKNGv8kYFnN96uzzT8DrgHmAPsBM5xzB7W4PmlS\nGoergSOAefg1/7u0w1ek2hqN6LgMmFjz/SgzW1Pz/VwzWwbgnLsF31huafCabT1+tMO1JYs0Dunv\n7+fymx/jph8u3nGzyRs+9eTvn2O7rTdpx+yHSu+LnLLIKQuvpfs6GjX+e/Fngl7vnHs7sGhggnNu\nMrDIObcz/gLg+wHzhzBP7azx2rrjqq+vj5t+uLgPOOmZpS+dd8I3frQCmJWN8Fk27cTLKYucsihI\no6N6+siP6gH4GH67/gQzm+ecOww4EX/Ez+1mdlaD+ekPmSstiyBK3gdcDWwMnA2clW0SKoveFzll\nkVMWBdGZu+UpNYsgSt4CJMDrgLuAw9M4/H1J5eh9kVMWOWVREJ3AVVFpHC7CH457IzAT+EUQJe8v\ntyoRaQet8ZenI7LITvQ6GvgG/jKO1wPHpnH4pzaW0RFZdAhlkVMWBVHjL09HZZFdsH0+/nj/v+DP\n+L0ijcM1dX+wNToqi5Ipi5yyKIg29QgAaRz+Cngn/lKO44DLgAeCKJlRamEi0nJa4y9Px2YRRMk2\nwFeBD2cPXQ+cmcbh4wXNsmOzKIGyyCmLgqjxl6fjswiiZE/gAuDv8PVeC5ydfTpopY7Poo2URU5Z\nFESNvzxdkUUQJaOA9wFfAHbD1/1dYC5wbzYeULO6Ios2URY5ZVEQNf7ydFUW2dE/7wPOxB8GCv4y\nj3OB69I4fLmJl++qLAqmLHLKoiBq/OXpyiyyBcA7gePxw3aPAp7Fnwm8AHhwBJ8CujKLgiiLnLIo\niBp/ebo+iyBKtsUP+/wRYGr28KPAvwLfTeNw8RBfquuzaCFlkVMWBVHjL0/PZBFEyQbAAfjhn0Ng\nbDZpEf7M4O8Cj9b5JNAzWbSAssgpi4Ko8ZenJ7MIomQKfl/AP+AXBgMLgd8BtwELgTvSOHy25sd6\nMosRUhY5ZVEQNf7y9HwWQZRMAv4eeD+wP7BpNmkNcD9wJ3DPNef8/fcnjB/T01kMQ8+/L4ZBWRRE\njb88lcoiiJLR+Et3Hoj/JPB2YDRAXx/097MIuAd/DYifAYvbNFxEp6nU+6IBZVEQNf7yVDqL7NPA\nnsCMN2/3qtMffvLPLwEb1jxlGfAQ/pDRB7Pbr0u+bkA7VPp9MYiyKIgaf3mURa4/iJJx+PMD9sRf\n7GcasCNrZ/Qy8Djw2KDb4jQOV7W14uLofZFTFgVR4y+PssitM4sgSiYAu5IvCHYBdgY2GvTUV4D/\nBp6suQ18/5s0Dl8qrPLW0/sipywKosZfHmWRG3IW2RASr8UvAHYmXxhsT77zePBr/wH4LfBUdvv9\noK+XdND+BL0vcsqiIGr85VEWuZZkEUTJpsB267m9ps48XsEvAP4A/A/wp5rbWt+34dOD3hc5ZVEQ\nNf7yKItc4VkEUTIGeDWwDbD1oPuBr6cOoY5l+IXBEuAZ/EVr1nVf+/WKYQxjofdFTlkURI2/PMoi\n1xFZZGcgbw5sWXObOuj7gcc2Y+gXMnoZvwBYil9wLB309V/vT/3oHvO/esVPD1jHc4ez8OgVHfG+\n6EVq/OVRFrmuyyLb1zAZmIJfCDS63wyYlP3MmBHMsh94EXgeeCG7DeXrwd+vAF7K7mu/fqkDD5Xt\nuvdFt1DjL4+yyFUmi2x003H4BcBk8oXBJGDy7EPedPm87z1y5qBpk4GNa24Tau5Ht7C8ldQsCFjH\nwqHO/Sv4Tza19yN+LFsIVeZ90W51G79zbhRwMfAW/B/kSDN7smZ6AJwBrAIuM7NLG8xPf8icssgp\ni9xwjnDqw4+FtK6Fwvq+3hAYP4z7ga9H8imlGWvGjhk96pWVq5ey9gLiFfwCatWg+0aPjeRn6j22\nKrutzm6rhnm/Glhd1ua7Ro3/UOBgM/u4c2468DkzOySbNgZ/8szb8B9B782e+7915qd/8JyyyCmL\nXEdmkQ25UW8hMRb/SWZsna+H9dj222yy16+fem7ROp63AX5BNCb7upWfetptDUNYWKRxuF0rZ7pB\ng+l7AbcCmNn9zrm31UzbCVhsZksBnHP3ADOBG1pZoIiUL9v0MrCfoF368Sfw1ZXtbxnN2guD2vtG\nj43kZwYWOIPv1/VYs88dGOG2ZRo1/kn4IwsGrHbOjTKzNdm0pTXTluO3RYqItE128t0a/CYYGYJG\nh6MtAybWPj9r+uCbfu20ifhL8ImISAdr1PjvxY+njnPu7fgrKg14HNjeObepc24sfjPPjxu8Xsdt\nuyyRssgpi5yyyCmLgjTaudtHflQPwMfwA2ZNMLN5zrmDgTPxC5D5ZnZJwfWKiEiT2n0cv4iIlGyo\np5yLiEiPUOMXEakYNX4RkYpR4xcRqZhGJ3C1RKMxf3pJNpTFZcC2+NPMzwF+BSzAn2TyCPApM+t3\nzs0GjsKfmn2Omd3inBsPXIUfHng58FEz+3Pbf5EWcc5tgb9Q+rvwv/8CKpgDgHPuc0CAP/PzIvzh\n0guoWB5ZP7gU2AH/u8/GD02wgIpkkQ2B81Uz29c590aa/N2zw+0vyJ670My+VG/+7VrjPwQYa2bv\nAE4F4jbNtwyHA0vMbCbwHuBb+N/3tOyxPiB0zk0FjgXeARwIfCU7H+IY4JfZc68ETi/hd2iJbCH4\nL/jT/PuA86lgDgDOuX2APbP/gX2AN1DR9wVwALCxmc0AvgScS4WycM6dDMzDrxhCa/4vvg0clmU6\n3Tm3W70a2tX41xrzBz+wW6+6Hn9uA/h8VwLTzOyu7LEfAO8G9gDuNbOVZrYMWIz/RPTXrLL7d7er\n8AJ8DbgEeDr7vqo5gG92DzvnvgekwH8Au1c0jxXA5Ow8ocn4ETerlMVi4FDyE9Sa+r9wzk3Er1j/\nJnv8Nhpk0q7Gv84xf9o077YysxfM7Pnsj3E9folc+7sOjGm0vrGOarPq2vGPnHNH4D/5LMwe6mPt\nMzErkUONzfEnP/4jcDRwNdXN4178iJ6P4z8RXkiFsjCzG/GbZAY0+7sP7q8NM2lX86035k/Pcc5t\nA/wXcKWZXYPfdjdgEvAcf5vJxHU8PvBYN/oYsL9z7k5gN+AKfPMbUJUcBvwZv+11lZk9gb94Se0/\nZ5XyOBm/Nuvw740rWXu8/yplAc33h8HPHXiN9WpX46835k9Pcc5tCSwETjazBdnDDznn9s6+fi9w\nF/AA8E7n3Djn3GT8MNePUJNVzXO7jpntbWb7mNm+wC+AjwC3Vi2HGvfg9/ngnNsK2Ai4o6J5bEy+\nhvos/iCTyv2P1Gjqdzez5cArzrk3ZJvPDqBBJm0ZsmFdY/5kaz09xzk3F/gAYDUPH4//ODsWf/Ga\n2dle+yPxe+1HAV82s5uyvfZXAK/GHwH14QYXt+l42Vr/HPz46vOobg7nAfvif8/PAb+lgnk45zYB\nLgdehV/TvwB/5FdlsnDOvQ642sze4ZzbniZ/9+wooQvwY/jfZmZn1Ju/xuoREamYntzBKiIi66fG\nLyJSMWr8IiIVo8YvIlIxavwiIhWjxi8iUjFq/CIiFaPGLyJSMf8HY8lobHrZGK4AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1890d2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_nn = neural_network([2,4,1])\n",
    "cost = []\n",
    "for i in xrange(10000):\n",
    "    my_nn.gradient_descent(x_or, y_or, 0.1)\n",
    "    cost.append(log_loss( y_or, my_nn.predict(x_or)))\n",
    "    \n",
    "print my_nn.predict(x_or)\n",
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.97019336e-01   3.70909096e-03   6.92049757e-05]\n",
      " [  9.96510516e-01   4.36764568e-03   7.60687200e-05]\n",
      " [  9.96926988e-01   3.90062610e-03   7.00883691e-05]\n",
      " [  9.96577631e-01   4.37212268e-03   7.36473885e-05]\n",
      " [  9.97095516e-01   3.66022952e-03   6.77296824e-05]\n",
      " [  9.97002148e-01   3.68555342e-03   6.91819783e-05]\n",
      " [  9.96998881e-01   3.86644011e-03   6.81410711e-05]\n",
      " [  9.96896552e-01   3.88006520e-03   7.06229181e-05]\n",
      " [  9.96406598e-01   4.64282958e-03   7.54481797e-05]\n",
      " [  9.96613757e-01   4.26113241e-03   7.45202609e-05]\n",
      " [  9.97043858e-01   3.63779581e-03   6.90556400e-05]\n",
      " [  9.96846706e-01   4.01898814e-03   7.03087314e-05]\n",
      " [  9.96622087e-01   4.27244355e-03   7.45181179e-05]\n",
      " [  9.97052057e-01   3.91780933e-03   6.78071933e-05]\n",
      " [  9.97161706e-01   3.44694094e-03   6.76561956e-05]\n",
      " [  9.97195652e-01   3.45081599e-03   6.66126774e-05]\n",
      " [  9.97135031e-01   3.50824202e-03   6.77759245e-05]\n",
      " [  9.96982617e-01   3.73476769e-03   6.97265221e-05]\n",
      " [  9.96939366e-01   3.72165490e-03   7.06677240e-05]\n",
      " [  9.97112871e-01   3.62709198e-03   6.73288389e-05]\n",
      " [  9.96620768e-01   4.15141562e-03   7.47861903e-05]\n",
      " [  9.97020119e-01   3.69623629e-03   6.88197596e-05]\n",
      " [  9.97284462e-01   3.58480235e-03   6.41808842e-05]\n",
      " [  9.96083504e-01   4.79028446e-03   7.91434110e-05]\n",
      " [  9.96351696e-01   4.66710925e-03   7.45310414e-05]\n",
      " [  9.96039989e-01   4.93854434e-03   8.13122769e-05]\n",
      " [  9.96646375e-01   4.14598372e-03   7.32970600e-05]\n",
      " [  9.96947451e-01   3.77905697e-03   7.02730080e-05]\n",
      " [  9.96935722e-01   3.78484800e-03   7.06736770e-05]\n",
      " [  9.96566774e-01   4.36751984e-03   7.36373843e-05]\n",
      " [  9.96339133e-01   4.60563308e-03   7.69059308e-05]\n",
      " [  9.96729144e-01   3.99130064e-03   7.34836670e-05]\n",
      " [  9.97280125e-01   3.55739151e-03   6.40146401e-05]\n",
      " [  9.97220044e-01   3.47364319e-03   6.59895883e-05]\n",
      " [  9.96613757e-01   4.26113241e-03   7.45202609e-05]\n",
      " [  9.96944968e-01   3.80120241e-03   7.06579021e-05]\n",
      " [  9.97012248e-01   3.65014656e-03   6.99499688e-05]\n",
      " [  9.96613757e-01   4.26113241e-03   7.45202609e-05]\n",
      " [  9.96764012e-01   4.19866702e-03   7.14525777e-05]\n",
      " [  9.96879298e-01   3.87689057e-03   7.11035919e-05]\n",
      " [  9.97047635e-01   3.67394957e-03   6.87630024e-05]\n",
      " [  9.93482949e-01   8.49872594e-03   1.05282021e-04]\n",
      " [  9.97003065e-01   3.94590400e-03   6.78981347e-05]\n",
      " [  9.96599331e-01   4.16796672e-03   7.33052853e-05]\n",
      " [  9.96788608e-01   4.02732994e-03   7.03933252e-05]\n",
      " [  9.96421052e-01   4.47505213e-03   7.66188039e-05]\n",
      " [  9.97114022e-01   3.66640003e-03   6.70215893e-05]\n",
      " [  9.96859892e-01   4.02925251e-03   7.03522046e-05]\n",
      " [  9.97058192e-01   3.64121574e-03   6.86733656e-05]\n",
      " [  9.96883749e-01   3.88364788e-03   7.11120561e-05]\n",
      " [  3.43703253e-03   9.94647735e-01   3.07325453e-03]\n",
      " [  3.45789090e-03   9.93939093e-01   3.36822655e-03]\n",
      " [  3.21136028e-03   9.93226791e-01   4.11654417e-03]\n",
      " [  2.95440826e-03   9.87457737e-01   7.81124078e-03]\n",
      " [  3.06923351e-03   9.91100671e-01   5.52242285e-03]\n",
      " [  2.87421432e-03   9.85156886e-01   9.29194419e-03]\n",
      " [  3.17095877e-03   9.90826259e-01   5.38102990e-03]\n",
      " [  4.47784200e-03   9.93184437e-01   2.66477211e-03]\n",
      " [  3.35726885e-03   9.94330651e-01   3.33553455e-03]\n",
      " [  3.29298120e-03   9.89450295e-01   5.74029661e-03]\n",
      " [  3.51412504e-03   9.93601422e-01   3.53513749e-03]\n",
      " [  3.45796934e-03   9.93018136e-01   3.78771564e-03]\n",
      " [  3.42795052e-03   9.94562733e-01   3.16838335e-03]\n",
      " [  2.81689374e-03   9.84681492e-01   9.81700958e-03]\n",
      " [  4.51236895e-03   9.93131520e-01   2.60751446e-03]\n",
      " [  3.53462921e-03   9.94546475e-01   3.00424157e-03]\n",
      " [  2.48262056e-03   9.61584912e-01   2.53424179e-02]\n",
      " [  3.62749171e-03   9.94381285e-01   2.98366308e-03]\n",
      " [  1.78491394e-03   8.26825416e-01   1.43670919e-01]\n",
      " [  3.56673074e-03   9.94188428e-01   3.14556027e-03]\n",
      " [  1.36604932e-03   4.50207010e-01   5.14074395e-01]\n",
      " [  3.64843607e-03   9.94331736e-01   2.97750505e-03]\n",
      " [  1.37643532e-03   5.10991609e-01   4.61995323e-01]\n",
      " [  3.10113597e-03   9.91366573e-01   5.30413848e-03]\n",
      " [  3.50443304e-03   9.94489125e-01   3.06994710e-03]\n",
      " [  3.47179753e-03   9.94492712e-01   3.10512681e-03]\n",
      " [  3.15456590e-03   9.92793964e-01   4.45369755e-03]\n",
      " [  2.14207026e-03   9.33425243e-01   4.96431817e-02]\n",
      " [  2.89432326e-03   9.85921386e-01   8.79490488e-03]\n",
      " [  4.55450497e-03   9.93255152e-01   2.63920797e-03]\n",
      " [  3.56493360e-03   9.94124186e-01   3.18362604e-03]\n",
      " [  3.73931366e-03   9.94253052e-01   2.94210853e-03]\n",
      " [  3.70152553e-03   9.94217328e-01   2.97020241e-03]\n",
      " [  8.18238350e-04   4.51074047e-02   9.59736680e-01]\n",
      " [  2.08901983e-03   8.96815330e-01   7.43977521e-02]\n",
      " [  3.45268979e-03   9.91923971e-01   4.26262001e-03]\n",
      " [  3.30254711e-03   9.93735860e-01   3.70410019e-03]\n",
      " [  3.02096218e-03   9.90610850e-01   5.94206409e-03]\n",
      " [  3.72129287e-03   9.93566089e-01   3.18525176e-03]\n",
      " [  3.22477403e-03   9.91438356e-01   4.99400890e-03]\n",
      " [  2.77699919e-03   9.82302743e-01   1.13273518e-02]\n",
      " [  3.14908861e-03   9.91212202e-01   5.25603119e-03]\n",
      " [  3.51919685e-03   9.94175020e-01   3.20365474e-03]\n",
      " [  4.23538137e-03   9.93559809e-01   2.75524166e-03]\n",
      " [  3.22143192e-03   9.91345820e-01   5.03231302e-03]\n",
      " [  3.68810758e-03   9.93909701e-01   3.08832161e-03]\n",
      " [  3.49350394e-03   9.93366495e-01   3.58263398e-03]\n",
      " [  3.48813413e-03   9.94283430e-01   3.18096358e-03]\n",
      " [  6.42263679e-03   9.90554480e-01   2.25822398e-03]\n",
      " [  3.50451207e-03   9.93566910e-01   3.48241827e-03]\n",
      " [  6.60308699e-04   1.35052895e-02   9.89115877e-01]\n",
      " [  6.79908385e-04   1.55650176e-02   9.87235624e-01]\n",
      " [  6.72539575e-04   1.51620259e-02   9.87699271e-01]\n",
      " [  6.82664902e-04   1.62882451e-02   9.86661876e-01]\n",
      " [  6.61975502e-04   1.37522796e-02   9.88912792e-01]\n",
      " [  6.60415343e-04   1.37536720e-02   9.88949824e-01]\n",
      " [  7.09452987e-04   1.80351747e-02   9.84684639e-01]\n",
      " [  6.72362472e-04   1.52343057e-02   9.87656173e-01]\n",
      " [  6.66586011e-04   1.44092672e-02   9.88371328e-01]\n",
      " [  6.65293351e-04   1.40850023e-02   9.88603342e-01]\n",
      " [  9.96185072e-04   1.27089345e-01   8.75412322e-01]\n",
      " [  6.96828818e-04   1.83497812e-02   9.84839020e-01]\n",
      " [  6.97996043e-04   1.85618061e-02   9.84646408e-01]\n",
      " [  6.68321421e-04   1.42058215e-02   9.88468491e-01]\n",
      " [  6.63753892e-04   1.36092515e-02   9.88968298e-01]\n",
      " [  6.83172847e-04   1.58476782e-02   9.86937595e-01]\n",
      " [  7.45852944e-04   2.70156208e-02   9.76931982e-01]\n",
      " [  6.71703256e-04   1.50532969e-02   9.87789883e-01]\n",
      " [  6.58478795e-04   1.35218851e-02   9.89156158e-01]\n",
      " [  7.50256429e-04   2.79227368e-02   9.76188587e-01]\n",
      " [  6.72478536e-04   1.49715267e-02   9.87825606e-01]\n",
      " [  6.86036020e-04   1.58197970e-02   9.86887050e-01]\n",
      " [  6.59899661e-04   1.36980535e-02   9.89001406e-01]\n",
      " [  9.58588263e-04   1.07461474e-01   8.97067847e-01]\n",
      " [  6.90421658e-04   1.72324271e-02   9.85784654e-01]\n",
      " [  7.69021221e-04   3.28581579e-02   9.71640748e-01]\n",
      " [  1.13393353e-03   2.40633003e-01   7.53511792e-01]\n",
      " [  1.09467504e-03   1.99364894e-01   7.97001515e-01]\n",
      " [  6.63852678e-04   1.39650266e-02   9.88728026e-01]\n",
      " [  1.07451216e-03   1.98864101e-01   8.01905171e-01]\n",
      " [  6.78174952e-04   1.60048432e-02   9.86982138e-01]\n",
      " [  9.21418813e-04   9.02594380e-02   9.15438441e-01]\n",
      " [  6.62057344e-04   1.37601161e-02   9.88909103e-01]\n",
      " [  1.38915017e-03   5.21723605e-01   4.49428327e-01]\n",
      " [  7.04251132e-04   1.96245979e-02   9.83726869e-01]\n",
      " [  6.68028502e-04   1.46579695e-02   9.88156977e-01]\n",
      " [  6.67139263e-04   1.38705333e-02   9.88699758e-01]\n",
      " [  7.50176810e-04   2.76337115e-02   9.76294903e-01]\n",
      " [  1.17502152e-03   2.69096193e-01   7.19095582e-01]\n",
      " [  7.69757765e-04   3.23852150e-02   9.71940727e-01]\n",
      " [  6.64934769e-04   1.40222532e-02   9.88657672e-01]\n",
      " [  8.08505174e-04   4.21355833e-02   9.62555195e-01]\n",
      " [  6.79908385e-04   1.55650176e-02   9.87235624e-01]\n",
      " [  6.63344019e-04   1.39083002e-02   9.88772768e-01]\n",
      " [  6.63922785e-04   1.38307207e-02   9.88808496e-01]\n",
      " [  7.00072681e-04   1.86165905e-02   9.84541731e-01]\n",
      " [  7.20230917e-04   2.20629391e-02   9.81494058e-01]\n",
      " [  7.76534230e-04   3.35089376e-02   9.70771644e-01]\n",
      " [  6.79371979e-04   1.49516350e-02   9.87648602e-01]\n",
      " [  7.69093138e-04   3.04544176e-02   9.73367392e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18bbe320>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAECCAYAAAAYfWtSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x189cf198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_nn = neural_network([4,8,3])\n",
    "cost = []\n",
    "for i in xrange(10000):\n",
    "    my_nn.gradient_descent(x_iris, y_iris, 0.1)\n",
    "    cost.append(log_loss( y_iris, my_nn.predict(x_iris)))\n",
    "    \n",
    "print my_nn.predict(x_iris)\n",
    "plt.plot(cost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
